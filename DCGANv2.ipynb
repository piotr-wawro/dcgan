{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14996,"status":"ok","timestamp":1652616546180,"user":{"displayName":"Piotr Wawro","userId":"00256984746504804507"},"user_tz":-120},"id":"e7pP2neRf_d5","outputId":"b3b4a246-eded-4dc0-c1f9-abd7391f271c"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2561,"status":"ok","timestamp":1652638604237,"user":{"displayName":"Piotr Wawro","userId":"00256984746504804507"},"user_tz":-120},"id":"s2sqis-pm-MQ"},"outputs":[{"data":{"text/plain":["'/device:GPU:0'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import tensorflow as tf\n","import keras\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import matplotlib.pyplot as plt\n","\n","from IPython import display\n","tf.test.gpu_device_name()"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":665,"status":"ok","timestamp":1652638607473,"user":{"displayName":"Piotr Wawro","userId":"00256984746504804507"},"user_tz":-120},"id":"Gpuq4XAYhLdl"},"outputs":[],"source":["# BASE_PATH = '/content/drive/Colab Notebooks'\n","BASE_PATH = '.'\n","BUFFER_SIZE = 30000\n","BATCH_SIZE = 32\n","EPOCHS = 50\n","NOISE_DIM = 128\n","SEED = tf.random.normal([16, NOISE_DIM])"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1652638610364,"user":{"displayName":"Piotr Wawro","userId":"00256984746504804507"},"user_tz":-120},"id":"IbfBk_HD4aGV"},"outputs":[],"source":["def make_generator_model():\n","  model = tf.keras.Sequential()\n","\n","  model.add(layers.Dense(8*8*128, use_bias=False, input_shape=(NOISE_DIM,)))\n","  model.add(layers.Reshape((8, 8, 128)))\n","\n","  model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n","  model.add(layers.LeakyReLU())\n","\n","  model.add(layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n","  model.add(layers.LeakyReLU())\n","\n","  model.add(layers.Conv2DTranspose(512, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n","  model.add(layers.LeakyReLU())\n","\n","  model.add(layers.Conv2D(3, (5, 5), padding='same', use_bias=False, activation='sigmoid'))\n","\n","  return model"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def make_generator_model():\n","  generator = keras.Sequential(\n","    [\n","        keras.Input(shape=(NOISE_DIM,)),\n","        layers.Dense(8 * 8 * 128),\n","        layers.Reshape((8, 8, 128)),\n","        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n","    ],\n","    name=\"generator\",\n","  )\n","\n","  return generator"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1652638612080,"user":{"displayName":"Piotr Wawro","userId":"00256984746504804507"},"user_tz":-120},"id":"267Oatxt54tK"},"outputs":[],"source":["def make_discriminator_model():\n","    model = tf.keras.Sequential()\n","    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[64, 64, 3]))\n","    model.add(layers.LeakyReLU())\n","\n","    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n","    model.add(layers.LeakyReLU())\n","\n","    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n","    model.add(layers.LeakyReLU())\n","\n","    model.add(layers.Flatten())\n","    model.add(layers.Dropout(0.3))\n","    model.add(layers.Dense(1))\n","\n","    return model"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def make_discriminator_model():\n","    discriminator = keras.Sequential(\n","    [\n","        keras.Input(shape=(64, 64, 3)),\n","        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Flatten(),\n","        layers.Dropout(0.2),\n","        layers.Dense(1, activation=\"sigmoid\"),\n","    ],\n","    name=\"discriminator\",\n","  )\n","\n","    return discriminator"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["class GAN(keras.Model):\n","  def __init__(self, generator, discriminator):\n","    super(GAN, self).__init__()\n","    self.generator = generator\n","    self.discriminator = discriminator\n","    self.generator_optimizers = tf.keras.optimizers.Adam(1e-4)\n","    self.discriminator_optimizers = tf.keras.optimizers.Adam(1e-4)\n","\n","  def train_step(self, real_images):\n","    if isinstance(real_images, tuple):\n","      real_images = real_images[0]\n","    batch_size = tf.shape(real_images)[0]\n","\n","    noise = tf.random.normal([batch_size, NOISE_DIM])\n","    generated_images = self.generator(noise, training=False)\n","\n","    x = tf.concat([real_images, generated_images], axis=0)\n","    y = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n","    y += 0.05 * tf.random.uniform(tf.shape(y))\n","\n","    with tf.GradientTape() as tape:\n","      y_pred = self.discriminator(x, training=True)\n","      loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n","\n","    gradients = tape.gradient(loss, self.discriminator.trainable_variables)\n","    self.discriminator_optimizers.apply_gradients(zip(gradients, self.discriminator.trainable_variables))\n","    self.compiled_metrics.update_state(y, y_pred)\n","    # self.compiled_metrics.metrics[0].update_state(y, y_pred)\n","\n","    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n","    y = tf.ones((BATCH_SIZE, 1))\n","\n","    with tf.GradientTape() as tape:\n","      x = self.generator(noise, training=True)\n","      y_pred = self.discriminator(x, training=False)\n","      loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n","\n","    gradients = tape.gradient(loss, self.generator.trainable_variables)\n","    self.generator_optimizers.apply_gradients(zip(gradients, self.generator.trainable_variables))\n","    # self.compiled_metrics.metrics[1].update_state(y, y_pred)\n","\n","    return {m.name: m.result() for m in self.metrics}\n","\n","  def call(self, x):\n","    return self.generator(x)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1652638619973,"user":{"displayName":"Piotr Wawro","userId":"00256984746504804507"},"user_tz":-120},"id":"qnjWBijThXzO"},"outputs":[],"source":["def generate_and_save_images(model, epoch, x):\n","  y = model(x, training=False)\n","\n","  fig = plt.figure(figsize=(4, 4))\n","\n","  for i in range(16):\n","      plt.subplot(4, 4, i+1)\n","      plt.imshow(y[i, :, :, :])\n","      plt.axis('off')\n","\n","  plt.savefig(f'{BASE_PATH}/images/image_at_epoch_{epoch}.png')\n","  plt.show()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 15747 files belonging to 1 classes.\n"]}],"source":["dataset = tf.keras.preprocessing.image_dataset_from_directory(\n","    \"cats\", label_mode=None, image_size=(64, 64), batch_size=BATCH_SIZE\n",")\n","\n","dataset = dataset.map(lambda x: x / 255.0)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":656,"status":"ok","timestamp":1652638624836,"user":{"displayName":"Piotr Wawro","userId":"00256984746504804507"},"user_tz":-120},"id":"ZO8f7-jgeLEG"},"outputs":[],"source":["generator_model = make_generator_model()\n","discriminator_model = make_discriminator_model()\n","\n","gan = GAN(generator_model, discriminator_model)\n","gan.compile(\n","    loss = tf.keras.losses.BinaryCrossentropy(),\n","    metrics = [tf.keras.metrics.BinaryAccuracy(name='discriminator'), tf.keras.metrics.BinaryAccuracy(name='generator')],\n","    run_eagerly=True\n",")\n","\n","checkpoint_dir = BASE_PATH + '/training_checkpoints'\n","checkpoint = tf.train.Checkpoint(gan=gan)\n","\n","ckptManager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=10)\n","ckptManager.restore_or_initialize()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" 31/493 [>.............................] - ETA: 2:57 - loss: 0.7107 - discriminator: 0.0000e+00 - generator: 0.0000e+00"]}],"source":["for i in range(50):\n","  gan.fit(dataset, epochs=1)\n","\n","  display.clear_output(wait=True)\n","  generate_and_save_images(model = gan.generator,\n","                           epoch = i,\n","                           x = SEED)\n","\n","  if (i+1) % 25 == 0:\n","    ckptManager.save()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"DCGANv2.ipynb","provenance":[]},"interpreter":{"hash":"c1080945a67b3e1e0eca6e9e436b63f3381c12303c6b2cc43db74709abeef6c8"},"kernelspec":{"display_name":"Python 3.10.2 ('venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"}},"nbformat":4,"nbformat_minor":0}
